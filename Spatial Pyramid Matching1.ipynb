{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0fKxneQADuPQ"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import sklearn\n",
        "from sklearn.cluster import KMeans\n",
        "import scipy.cluster.vq as vq\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import struct\n",
        "import pickle\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "from sklearn import neighbors, metrics\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "RrCVmqNQDuPZ",
        "outputId": "54ac3d5f-8de6-4acd-8e7d-4fa3b6e79e04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "expected an indented block after function definition on line 82 (<ipython-input-40-b18a8e2a9fd6>, line 83)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-40-b18a8e2a9fd6>\"\u001b[0;36m, line \u001b[0;32m83\u001b[0m\n\u001b[0;31m    \"\"\"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 82\n"
          ]
        }
      ],
      "source": [
        "# !git clone https://github.com/CyrusChiu/Image-recognition\n",
        "\n",
        "DSIFT_STEP_SIZE = 4\n",
        "\n",
        "\n",
        "def extract_sift_descriptors(img):\n",
        "    \"\"\"\n",
        "    Input BGR numpy array\n",
        "    Return SIFT descriptors for an image\n",
        "    Return None if there's no descriptor detected\n",
        "    \"\"\"\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    sift = cv2.SIFT_create()\n",
        "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
        "    return descriptors\n",
        "\n",
        "\n",
        "def extract_DenseSift_descriptors(img):\n",
        "    \"\"\"\n",
        "    Input BGR numpy array\n",
        "    Return Dense SIFT descriptors for an image\n",
        "    Return None if there's no descriptor detected\n",
        "    \"\"\"\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    sift = cv2.SIFT_create()\n",
        "\n",
        "    # opencv docs DenseFeatureDetector\n",
        "    # opencv 2.x code\n",
        "    #dense.setInt('initXyStep',8) # each step is 8 pixel\n",
        "    #dense.setInt('initImgBound',8)\n",
        "    #dense.setInt('initFeatureScale',16) # each grid is 16*16\n",
        "    disft_step_size = DSIFT_STEP_SIZE\n",
        "    keypoints = [cv2.KeyPoint(x, y, disft_step_size)\n",
        "            for y in range(0, gray.shape[0], disft_step_size)\n",
        "                for x in range(0, gray.shape[1], disft_step_size)]\n",
        "\n",
        "    keypoints, descriptors = sift.compute(gray, keypoints)\n",
        "\n",
        "    #keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
        "    return [keypoints, descriptors]\n",
        "\n",
        "\n",
        "def build_codebook(X, voc_size):\n",
        "    \"\"\"\n",
        "    Inupt a list of feature descriptors\n",
        "    voc_size is the \"K\" in K-means, k is also called vocabulary size\n",
        "    Return the codebook/dictionary\n",
        "    \"\"\"\n",
        "    features = np.vstack((descriptor for descriptor in X))\n",
        "    kmeans = KMeans(n_clusters=voc_size, n_jobs=-2)\n",
        "    kmeans.fit(features)\n",
        "    codebook = kmeans.cluster_centers_.squeeze()\n",
        "    return codebook\n",
        "\n",
        "\n",
        "def input_vector_encoder(feature, codebook):\n",
        "    \"\"\"\n",
        "    Input all the local feature of the image\n",
        "    Pooling (encoding) by codebook and return\n",
        "    \"\"\"\n",
        "    code, _ = vq.vq(feature, codebook)\n",
        "    word_hist, bin_edges = np.histogram(code, bins=range(codebook.shape[0] + 1), normed=True)\n",
        "    return word_hist\n",
        "\n",
        "def load_cifar10_data(dataset):\n",
        "    if dataset == 'train':\n",
        "        with open('/content/Image-recognition/cifar10/train/train.txt','r') as f:\n",
        "            paths = f.readlines()\n",
        "    if dataset == 'test':\n",
        "        with open('/content/Image-recognition/cifar10/test/test.txt','r') as f:\n",
        "            paths = f.readlines()\n",
        "\n",
        "    x, y = [], []\n",
        "    for each in paths:\n",
        "        each = each.strip()\n",
        "        path, label = each.split(' ')\n",
        "        img = cv2.imread(path)\n",
        "        x.append(img)\n",
        "        y.append(label)\n",
        "    return [x, y]\n",
        "\n",
        "def build_spatial_pyramid(image, descriptor, level):\n",
        "    \"\"\"\n",
        "    Rebuild the descriptors according to the level of pyramid\n",
        "    \"\"\"\n",
        "assert 0 <= level <= 2, \"Level Error\"\n",
        "step_size = DSIFT_STEP_SIZE\n",
        "    from utils import DSIFT_STEP_SIZE as s\n",
        "    assert s == step_size, \"step_size must equal to DSIFT_STEP_SIZE\\\n",
        "                            in utils.extract_DenseSift_descriptors()\"\n",
        "    h = image.shape[0] / step_size\n",
        "    w = image.shape[1] / step_size\n",
        "    idx_crop = np.array(range(len(descriptor))).reshape(h,w)\n",
        "    size = idx_crop.itemsize\n",
        "    height, width = idx_crop.shape\n",
        "    bh, bw = 2**(3-level), 2**(3-level)\n",
        "    shape = (height/bh, width/bw, bh, bw)\n",
        "    strides = size * np.array([width*bh, bw, width, 1])\n",
        "    crops = np.lib.stride_tricks.as_strided(\n",
        "            idx_crop, shape=shape, strides=strides)\n",
        "    des_idxs = [col_block.flatten().tolist() for row_block in crops\n",
        "                for col_block in row_block]\n",
        "    pyramid = []\n",
        "    for idxs in des_idxs:\n",
        "        pyramid.append(np.asarray([descriptor[idx] for idx in idxs]))\n",
        "    return pyramid\n",
        "\n",
        "def spatial_pyramid_matching(image, descriptor, codebook, level):\n",
        "    pyramid = []\n",
        "    if level == 0:\n",
        "        pyramid += build_spatial_pyramid(image, descriptor, level=0)\n",
        "        code = [input_vector_encoder(crop, codebook) for crop in pyramid]\n",
        "        return np.asarray(code).flatten()\n",
        "    if level == 1:\n",
        "        pyramid += build_spatial_pyramid(image, descriptor, level=0)\n",
        "        pyramid += build_spatial_pyramid(image, descriptor, level=1)\n",
        "        code = [input_vector_encoder(crop, codebook) for crop in pyramid]\n",
        "        code_level_0 = 0.5 * np.asarray(code[0]).flatten()\n",
        "        code_level_1 = 0.5 * np.asarray(code[1:]).flatten()\n",
        "        return np.concatenate((code_level_0, code_level_1))\n",
        "    if level == 2:\n",
        "        pyramid += build_spatial_pyramid(image, descriptor, level=0)\n",
        "        pyramid += build_spatial_pyramid(image, descriptor, level=1)\n",
        "        pyramid += build_spatial_pyramid(image, descriptor, level=2)\n",
        "        code = [input_vector_encoder(crop, codebook) for crop in pyramid]\n",
        "        code_level_0 = 0.25 * np.asarray(code[0]).flatten()\n",
        "        code_level_1 = 0.25 * np.asarray(code[1:5]).flatten()\n",
        "        code_level_2 = 0.5 * np.asarray(code[5:]).flatten()\n",
        "        return np.concatenate((code_level_0, code_level_1, code_level_2))\n",
        "\n",
        "\n",
        "VOC_SIZE = 100\n",
        "PYRAMID_LEVEL = 1\n",
        "\n",
        "DSIFT_STEP_SIZE = 4\n",
        "# DSIFT_STEP_SIZE is related to the function\n",
        "# extract_DenseSift_descriptors in utils.py\n",
        "# and build_spatial_pyramid in spm.py\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "\n",
        "    x_train, y_train = load_cifar10_data(dataset='train')\n",
        "    x_test, y_test = load_cifar10_data(dataset='test')\n",
        "\n",
        "    print (\"Dense SIFT feature extraction\")\n",
        "    x_train_feature = [extract_DenseSift_descriptors(img) for img in x_train]\n",
        "    x_test_feature = [extract_DenseSift_descriptors(img) for img in x_test]\n",
        "    x_train_kp, x_train_des = zip(*x_train_feature)\n",
        "    x_test_kp, x_test_des = zip(*x_test_feature)\n",
        "\n",
        "    print (\"Train/Test split: {:d}/{:d}\".format(len(y_train), len(y_test)))\n",
        "    print (\"Codebook Size: {:d}\".format(VOC_SIZE))\n",
        "    print (\"Pyramid level: {:d}\".format(PYRAMID_LEVEL))\n",
        "    print (\"Building the codebook, it will take some time\")\n",
        "    codebook = build_codebook(x_train_des, VOC_SIZE)\n",
        "    import cPickle\n",
        "    with open('./spm_lv1_codebook.pkl','w') as f:\n",
        "        cPickle.dump(codebook, f)\n",
        "\n",
        "    print (\"Spatial Pyramid Matching encoding\")\n",
        "    x_train = [spatial_pyramid_matching(x_train[i],\n",
        "                                        x_train_des[i],\n",
        "                                        codebook,\n",
        "                                        level=PYRAMID_LEVEL)\n",
        "                                        for i in xrange(len(x_train))]\n",
        "\n",
        "    x_test = [spatial_pyramid_matching(x_test[i],\n",
        "                                       x_test_des[i],\n",
        "                                       codebook,\n",
        "                                       level=PYRAMID_LEVEL) for i in xrange(len(x_test))]\n",
        "\n",
        "    x_train = np.asarray(x_train)\n",
        "    x_test = np.asarray(x_test)\n",
        "\n",
        "    svm_classifier(x_train, y_train, x_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Lw1E3OgNDuPb"
      },
      "outputs": [],
      "source": [
        "def extract_DenseSift_descriptors(img):\n",
        "\n",
        "    gray = img\n",
        "\n",
        "    sift = cv2.SIFT_create()\n",
        "    disft_step_size = DSIFT_STEP_SIZE\n",
        "    keypoints = [cv2.KeyPoint(x, y, disft_step_size)\n",
        "            for y in range(0, gray.shape[0], disft_step_size)\n",
        "                for x in range(0, gray.shape[1], disft_step_size)]\n",
        "\n",
        "    keypoints, descriptors = sift.compute(gray, keypoints)\n",
        "\n",
        "    return [keypoints, descriptors]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "D8XldzrHDuPc"
      },
      "outputs": [],
      "source": [
        "def svm_classifier(x_train, y_train, x_test=None, y_test=None):\n",
        "\n",
        "    C_range = 10.0 ** np.arange(-3, 3)\n",
        "    gamma_range = 10.0 ** np.arange(-3, 3)\n",
        "    param_grid = dict(gamma=gamma_range.tolist(), C=C_range.tolist())\n",
        "\n",
        "    # Grid search for C, gamma, 5-fold CV\n",
        "    print(\"Tuning hyper-parameters\\n\")\n",
        "    clf = GridSearchCV(svm.SVC(), param_grid, cv=5, n_jobs=-2)\n",
        "    clf.fit(x_train, y_train)\n",
        "    print(\"Best parameters set found on development set:\\n\")\n",
        "    print(clf.best_estimator_)\n",
        "    print(\"\\nGrid scores on development set:\\n\")\n",
        "    means = clf.cv_results_['mean_test_score']\n",
        "    stds = clf.cv_results_['std_test_score']\n",
        "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
        "              % (mean, std * 2, params))\n",
        "    print(\"\\nDetailed classification report:\\n\")\n",
        "    print(\"The model is trained on the full development set.\")\n",
        "    print(\"The scores are computed on the full evaluation set.\\n\")\n",
        "    y_true, y_pred = y_test, clf.predict(x_test)\n",
        "    #print(classification_report(y_true, y_pred, target_names=get_label()))\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    return y_true, y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "llJFTL21DuPe"
      },
      "outputs": [],
      "source": [
        "def build_codebook(X, voc_size):\n",
        "\n",
        "    features = np.vstack([descriptor for descriptor in X])\n",
        "    kmeans = KMeans(n_clusters=voc_size)\n",
        "    kmeans.fit(features)\n",
        "    codebook = kmeans.cluster_centers_.squeeze()\n",
        "    print(\"Codebook Building Complete\")\n",
        "    return codebook\n",
        "\n",
        "def input_vector_encoder(feature, codebook):\n",
        "    \"\"\"\n",
        "    Input all the local feature of the image\n",
        "    Pooling (encoding) by codebook and return\n",
        "    \"\"\"\n",
        "    code, _ = vq.vq(feature, codebook)\n",
        "    word_hist, bin_edges = np.histogram(code, bins=range(codebook.shape[0] + 1), density=True)\n",
        "    return word_hist\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5JeVqOXgc_br"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "GabId2acDuPg"
      },
      "outputs": [],
      "source": [
        "def build_spatial_pyramid(image, descriptor, level):\n",
        "    \"\"\"\n",
        "    Rebuild the descriptors according to the level of pyramid\n",
        "    \"\"\"\n",
        "    assert 0 <= level <= 2, \"Level Error\"\n",
        "    step_size = DSIFT_STEP_SIZE\n",
        "    #from utils import DSIFT_STEP_SIZE as s\n",
        "    s = 4\n",
        "    assert s == step_size, \"step_size must equal to DSIFT_STEP_SIZE in utils.extract_DenseSift_descriptors()\"\n",
        "    h = image.shape[0] // step_size\n",
        "    w = image.shape[1] // step_size\n",
        "    idx_crop = np.array(range(len(descriptor))).reshape(h,w)\n",
        "    size = idx_crop.itemsize\n",
        "    height, width = idx_crop.shape\n",
        "    bh, bw = 2**(3-level), 2**(3-level)\n",
        "    shape = (height//bh, width//bw, bh, bw)\n",
        "    strides = size * np.array([width*bh, bw, width, 1])\n",
        "    crops = np.lib.stride_tricks.as_strided(\n",
        "            idx_crop, shape=shape, strides=strides)\n",
        "    des_idxs = [col_block.flatten().tolist() for row_block in crops\n",
        "                for col_block in row_block]\n",
        "    pyramid = []\n",
        "    for idxs in des_idxs:\n",
        "        pyramid.append(np.asarray([descriptor[idx] for idx in idxs]))\n",
        "    return pyramid\n",
        "\n",
        "\n",
        "# In[3]:\n",
        "\n",
        "\n",
        "def spatial_pyramid_matching(image, descriptor, codebook, level):\n",
        "    pyramid = []\n",
        "    if level == 0:\n",
        "        pyramid += build_spatial_pyramid(image, descriptor, level=0)\n",
        "        code = [input_vector_encoder(crop, codebook) for crop in pyramid]\n",
        "        return np.asarray(code).flatten()\n",
        "    if level == 1:\n",
        "        pyramid += build_spatial_pyramid(image, descriptor, level=0)\n",
        "        pyramid += build_spatial_pyramid(image, descriptor, level=1)\n",
        "        code = [input_vector_encoder(crop, codebook) for crop in pyramid]\n",
        "        code_level_0 = 0.5 * np.asarray(code[0]).flatten()\n",
        "        code_level_1 = 0.5 * np.asarray(code[1:]).flatten()\n",
        "        return np.concatenate((code_level_0, code_level_1))\n",
        "    if level == 2:\n",
        "        pyramid += build_spatial_pyramid(image, descriptor, level=0)\n",
        "        pyramid += build_spatial_pyramid(image, descriptor, level=1)\n",
        "        pyramid += build_spatial_pyramid(image, descriptor, level=2)\n",
        "        code = [input_vector_encoder(crop, codebook) for crop in pyramid]\n",
        "        code_level_0 = 0.25 * np.asarray(code[0]).flatten()\n",
        "        code_level_1 = 0.25 * np.asarray(code[1:5]).flatten()\n",
        "        code_level_2 = 0.5 * np.asarray(code[5:]).flatten()\n",
        "        return np.concatenate((code_level_0, code_level_1, code_level_2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "yDbv9BesDuPh"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    accuracy = np.mean(np.max(cm,axis=1))\n",
        "    print(accuracy)\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "wiIAQtD0DuPm"
      },
      "outputs": [],
      "source": [
        "x_train, y_train = load_cifar10_data(dataset='train')\n",
        "x_test, y_test = load_cifar10_data(dataset='test')\n",
        "\n",
        "x_train = np.asarray(x_train)\n",
        "x_test = np.asarray(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "kg30DZC2DuPn",
        "outputId": "bd811502-25b5-4c3d-c205-0eb1fa58fcbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000,)\n",
            "(10000,)\n"
          ]
        }
      ],
      "source": [
        "# x_train = x_train[:10000,:,:]\n",
        "# x_test = x_test[:2000,:,:]\n",
        "# y_train = y_train[:10000]\n",
        "# y_test = y_test[:2000]\n",
        "print (x_train.shape)\n",
        "print (x_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "B5X1qlPPDuPn",
        "outputId": "17e2c72e-6092-4049-af53-92716893b24e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'shape'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-bac44ea0e62d>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mDSIFT_STEP_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mx_train_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mextract_DenseSift_descriptors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mx_test_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mextract_DenseSift_descriptors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mx_train_kp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_des\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx_train_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-bac44ea0e62d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mDSIFT_STEP_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mx_train_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mextract_DenseSift_descriptors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mx_test_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mextract_DenseSift_descriptors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mx_train_kp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_des\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx_train_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-990dfb55c65a>\u001b[0m in \u001b[0;36mextract_DenseSift_descriptors\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdisft_step_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDSIFT_STEP_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     keypoints = [cv2.KeyPoint(x, y, disft_step_size)\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisft_step_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                 for x in range(0, gray.shape[1], disft_step_size)]\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ],
      "source": [
        "VOC_SIZE = 100\n",
        "PYRAMID_LEVEL = 1\n",
        "DSIFT_STEP_SIZE = 4\n",
        "\n",
        "x_train_feature = [extract_DenseSift_descriptors(img) for img in x_train]\n",
        "x_test_feature = [extract_DenseSift_descriptors(img) for img in x_test]\n",
        "x_train_kp, x_train_des = zip(*x_train_feature)\n",
        "x_test_kp, x_test_des = zip(*x_test_feature)\n",
        "print (\"Train/Test split: {:d}/{:d}\".format(len(y_train), len(y_test)))\n",
        "print (\"Codebook Size: {:d}\".format(VOC_SIZE))\n",
        "print (\"Pyramid level: {:d}\".format(PYRAMID_LEVEL))\n",
        "print (\"Building the codebook, it will take some time\")\n",
        "codebook = build_codebook(x_train_des, VOC_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "TTqoBc1QDuPo",
        "outputId": "6799fde5-0672-43ac-ce65-0e9baf6e8d63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'codebook' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-c1d2d36dd8d8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./spm_lv1_codebook.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Spatial Pyramid Matching encoding\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'codebook' is not defined"
          ]
        }
      ],
      "source": [
        "with open('./spm_lv1_codebook.pkl','wb') as f:\n",
        "    pickle.dump(codebook, f)\n",
        "\n",
        "print (\"Spatial Pyramid Matching encoding\")\n",
        "print (x_train.shape)\n",
        "print (x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "X4WZiWRuDuPp"
      },
      "outputs": [],
      "source": [
        "# import pickle\n",
        "# with open('./spm_lv1_codebook.pkl','rb') as f:\n",
        "#     codebook=pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "pbHhvH7ZDuPp",
        "outputId": "61c888a9-322c-4e6f-ef2d-c2cdace90e7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'x_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-c48e2ed6ceef>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                                     \u001b[0mcodebook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                     level=PYRAMID_LEVEL)\n\u001b[0;32m----> 5\u001b[0;31m                                     for i in range(len(x_train))]\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mspatial_pyramid_matching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test_des\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcodebook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPYRAMID_LEVEL\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
          ]
        }
      ],
      "source": [
        "x_train = [spatial_pyramid_matching(x_train[i],\n",
        "                                    x_train_des[i],\n",
        "                                    codebook,\n",
        "                                    level=PYRAMID_LEVEL)\n",
        "                                    for i in range(len(x_train))]\n",
        "\n",
        "x_test = [spatial_pyramid_matching(x_test[i],x_test_des[i],codebook,level=PYRAMID_LEVEL) for i in range(len(x_test))]\n",
        "\n",
        "x_train = np.asarray(x_train)\n",
        "x_test = np.asarray(x_test)\n",
        "\n",
        "y_true,y_pred = svm_classifier(x_train, y_train, x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JO77c1EhDuPq"
      },
      "outputs": [],
      "source": [
        "cm = metrics.confusion_matrix(y_true, y_pred)\n",
        "accuracy=plot_confusion_matrix(cm,[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"],normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zak_jJsNDuPq"
      },
      "outputs": [],
      "source": [
        "accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZH_0StlDuPq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
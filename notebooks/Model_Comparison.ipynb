{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Model Comparison\n",
    "\n",
    "This notebook provides a unified comparison of all classification methods implemented in this project.\n",
    "\n",
    "## Contents\n",
    "1. Setup & Data Loading\n",
    "2. Train All Models\n",
    "3. Evaluate & Compare\n",
    "4. Visualizations\n",
    "5. Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if running on Colab\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    !pip install -q torch torchvision scikit-learn matplotlib seaborn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.models import LeNet, AlexNet, SimpleCNN, count_parameters\n",
    "from src.data import get_mnist_loaders\n",
    "from src.train import Trainer, create_optimizer\n",
    "from src.evaluate import Evaluator\n",
    "from src.visualize import (\n",
    "    plot_training_history,\n",
    "    plot_confusion_matrix,\n",
    "    plot_sample_predictions,\n",
    "    plot_model_comparison,\n",
    "    plot_misclassified_samples,\n",
    ")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "train_loader, test_loader, val_loader = get_mnist_loaders(\n",
    "    batch_size=64,\n",
    "    augment=False,\n",
    "    validation_split=0.1,\n",
    "    data_dir='../data'\n",
    ")\n",
    "\n",
    "print(f'Training batches: {len(train_loader)}')\n",
    "print(f'Validation batches: {len(val_loader)}')\n",
    "print(f'Test batches: {len(test_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(images[i].squeeze(), cmap='gray')\n",
    "    ax.set_title(f'Label: {labels[i].item()}')\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Sample MNIST Images', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classical Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for sklearn (flatten images)\n",
    "def prepare_sklearn_data(loader, max_samples=None):\n",
    "    \"\"\"Flatten images for sklearn classifiers.\"\"\"\n",
    "    X, y = [], []\n",
    "    for images, labels in loader:\n",
    "        X.append(images.view(images.size(0), -1).numpy())\n",
    "        y.append(labels.numpy())\n",
    "        if max_samples and len(y) * images.size(0) >= max_samples:\n",
    "            break\n",
    "    X = np.vstack(X)\n",
    "    y = np.hstack(y)\n",
    "    if max_samples:\n",
    "        X, y = X[:max_samples], y[:max_samples]\n",
    "    return X, y\n",
    "\n",
    "# Use subset for faster classical method training\n",
    "X_train, y_train = prepare_sklearn_data(train_loader, max_samples=10000)\n",
    "X_test, y_test = prepare_sklearn_data(test_loader)\n",
    "\n",
    "print(f'Training set: {X_train.shape}')\n",
    "print(f'Test set: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbors with different distance metrics\n",
    "classical_results = {}\n",
    "\n",
    "# KNN - Euclidean\n",
    "print('Training KNN (Euclidean)...')\n",
    "start = time.time()\n",
    "knn_euclidean = KNeighborsClassifier(n_neighbors=3, metric='euclidean', n_jobs=-1)\n",
    "knn_euclidean.fit(X_train, y_train)\n",
    "knn_euc_pred = knn_euclidean.predict(X_test)\n",
    "knn_euc_acc = accuracy_score(y_test, knn_euc_pred) * 100\n",
    "knn_euc_time = time.time() - start\n",
    "classical_results['KNN (Euclidean)'] = {'accuracy': knn_euc_acc, 'time': knn_euc_time}\n",
    "print(f'  Accuracy: {knn_euc_acc:.2f}% (Time: {knn_euc_time:.1f}s)')\n",
    "\n",
    "# KNN - Manhattan\n",
    "print('Training KNN (Manhattan)...')\n",
    "start = time.time()\n",
    "knn_manhattan = KNeighborsClassifier(n_neighbors=3, metric='manhattan', n_jobs=-1)\n",
    "knn_manhattan.fit(X_train, y_train)\n",
    "knn_man_pred = knn_manhattan.predict(X_test)\n",
    "knn_man_acc = accuracy_score(y_test, knn_man_pred) * 100\n",
    "knn_man_time = time.time() - start\n",
    "classical_results['KNN (Manhattan)'] = {'accuracy': knn_man_acc, 'time': knn_man_time}\n",
    "print(f'  Accuracy: {knn_man_acc:.2f}% (Time: {knn_man_time:.1f}s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM (using smaller subset due to computational cost)\n",
    "print('Training SVM (RBF kernel)...')\n",
    "start = time.time()\n",
    "svm = SVC(kernel='rbf', C=10, gamma='scale')\n",
    "svm.fit(X_train[:5000], y_train[:5000])  # Smaller subset\n",
    "svm_pred = svm.predict(X_test)\n",
    "svm_acc = accuracy_score(y_test, svm_pred) * 100\n",
    "svm_time = time.time() - start\n",
    "classical_results['SVM (RBF)'] = {'accuracy': svm_acc, 'time': svm_time}\n",
    "print(f'  Accuracy: {svm_acc:.2f}% (Time: {svm_time:.1f}s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_deep_model(model_class, model_name, epochs=10, lr=0.001):\n",
    "    \"\"\"Train a deep learning model and return results.\"\"\"\n",
    "    print(f'\\nTraining {model_name}...')\n",
    "    \n",
    "    model = model_class().to(device)\n",
    "    total_params, trainable_params = count_parameters(model)\n",
    "    print(f'  Parameters: {trainable_params:,}')\n",
    "    \n",
    "    optimizer = create_optimizer(model, 'adam', lr=lr)\n",
    "    trainer = Trainer(model, optimizer, device=device)\n",
    "    \n",
    "    start = time.time()\n",
    "    history = trainer.fit(\n",
    "        train_loader,\n",
    "        val_loader=val_loader,\n",
    "        epochs=epochs,\n",
    "        verbose=True\n",
    "    )\n",
    "    train_time = time.time() - start\n",
    "    \n",
    "    # Evaluate\n",
    "    evaluator = Evaluator(model, device=device)\n",
    "    metrics = evaluator.evaluate(test_loader)\n",
    "    \n",
    "    print(f'  Test Accuracy: {metrics[\"accuracy\"]:.2f}%')\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'history': history,\n",
    "        'metrics': metrics,\n",
    "        'accuracy': metrics['accuracy'],\n",
    "        'time': train_time,\n",
    "        'params': trainable_params\n",
    "    }\n",
    "\n",
    "# Train all deep learning models\n",
    "deep_results = {}\n",
    "\n",
    "deep_results['SimpleCNN'] = train_deep_model(SimpleCNN, 'SimpleCNN', epochs=10)\n",
    "deep_results['LeNet'] = train_deep_model(LeNet, 'LeNet', epochs=10)\n",
    "deep_results['AlexNet'] = train_deep_model(AlexNet, 'AlexNet', epochs=10, lr=0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all results\n",
    "all_results = {}\n",
    "all_results.update(classical_results)\n",
    "for name, result in deep_results.items():\n",
    "    all_results[name] = {'accuracy': result['accuracy'], 'time': result['time']}\n",
    "\n",
    "# Create comparison DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "comparison_df = pd.DataFrame([\n",
    "    {'Model': name, 'Accuracy (%)': data['accuracy'], 'Training Time (s)': data['time']}\n",
    "    for name, data in all_results.items()\n",
    "]).sort_values('Accuracy (%)', ascending=False)\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('FINAL RESULTS COMPARISON')\n",
    "print('='*60)\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy comparison bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "models = comparison_df['Model'].tolist()\n",
    "accuracies = comparison_df['Accuracy (%)'].tolist()\n",
    "colors = ['#2ecc71' if acc > 95 else '#3498db' if acc > 90 else '#e74c3c' for acc in accuracies]\n",
    "\n",
    "bars = ax.barh(models, accuracies, color=colors)\n",
    "ax.set_xlabel('Accuracy (%)', fontsize=12)\n",
    "ax.set_title('Model Comparison - MNIST Classification', fontsize=14)\n",
    "ax.set_xlim(60, 100)\n",
    "\n",
    "# Add value labels\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    ax.text(acc + 0.5, bar.get_y() + bar.get_height()/2, f'{acc:.1f}%',\n",
    "            va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/accuracy_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves for deep learning models\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for ax, (name, result) in zip(axes, deep_results.items()):\n",
    "    history = result['history']\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    ax.plot(epochs, history['train_acc'], 'b-', label='Train')\n",
    "    ax.plot(epochs, history['val_acc'], 'r-', label='Validation')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Accuracy (%)')\n",
    "    ax.set_title(f'{name} Training Progress')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrices for all models\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Classical models\n",
    "cms = [\n",
    "    ('KNN (Euclidean)', confusion_matrix(y_test, knn_euc_pred)),\n",
    "    ('KNN (Manhattan)', confusion_matrix(y_test, knn_man_pred)),\n",
    "    ('SVM (RBF)', confusion_matrix(y_test, svm_pred)),\n",
    "]\n",
    "\n",
    "# Deep learning models\n",
    "for name, result in deep_results.items():\n",
    "    cms.append((name, result['metrics']['confusion_matrix']))\n",
    "\n",
    "for ax, (name, cm) in zip(axes.flat, cms):\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "                xticklabels=range(10), yticklabels=range(10))\n",
    "    ax.set_title(name)\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('True')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/confusion_matrices.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze misclassified samples for best model\n",
    "best_model_name = 'AlexNet'\n",
    "best_model = deep_results[best_model_name]['model']\n",
    "\n",
    "evaluator = Evaluator(best_model, device=device)\n",
    "misclassified = evaluator.get_misclassified(test_loader, n_samples=20)\n",
    "\n",
    "print(f'Total misclassified samples: {len(evaluator.get_misclassified(test_loader))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize misclassified samples\n",
    "fig = plot_misclassified_samples(\n",
    "    misclassified,\n",
    "    n_samples=15,\n",
    "    save_path='../results/misclassified_samples.png'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Key Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*60)\n",
    "print('KEY INSIGHTS')\n",
    "print('='*60)\n",
    "\n",
    "print('''\n",
    "1. DEEP LEARNING SUPERIORITY\n",
    "   - CNNs (AlexNet, LeNet) significantly outperform classical methods\n",
    "   - Learned features capture digit patterns better than raw pixels\n",
    "\n",
    "2. DISTANCE METRIC IMPACT\n",
    "   - Euclidean distance outperforms Manhattan for KNN on MNIST\n",
    "   - This suggests pixel intensities benefit from L2 normalization\n",
    "\n",
    "3. EFFICIENCY VS ACCURACY\n",
    "   - LeNet achieves near-AlexNet accuracy with 1% of parameters\n",
    "   - SimpleCNN offers good balance for resource-constrained deployment\n",
    "\n",
    "4. COMMON ERROR PATTERNS\n",
    "   - 4 vs 9: Similar loop structure\n",
    "   - 3 vs 5: Curved segments confusion\n",
    "   - 7 vs 1: Stroke angle variations\n",
    "\n",
    "5. PRACTICAL RECOMMENDATIONS\n",
    "   - For accuracy: Use AlexNet or ensemble\n",
    "   - For speed: Use LeNet or SimpleCNN\n",
    "   - For interpretability: KNN provides neighbor-based explanations\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final results\n",
    "comparison_df.to_csv('../results/model_comparison.csv', index=False)\n",
    "print('Results saved to ../results/model_comparison.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
